# Motif-SNN

Network architectures and learning principles have been critical in the development of complex cognitive capabilities in artificial neural networks (ANNs). Spiking neural networks (SNNs) are a subset of ANNs that incorporate additional biological features such as dynamic spiking neurons, biologically specified architectures, and efficient and useful paradigms. Here we focus more on network architectures and propose a Motif-topology improved SNN (M-SNN), which is further verified efficient in explaining key cognitive phenomenons such as the cocktail party effect (a typical multi-sensory integration task) and McGurk effect (a typical noise-robust speech-recognition task). The main reason it works is mainly caused by the meta operator called 3-node network motifs, which is borrowed from the biological network. These spatial and temporal motifs are first generated from the pre-training of spatial (e.g., MNIST) and temporal (e.g., TIDigits) datasets, respectively, and then applied to the previously introduced two cognitive effect tasks. The experimental results showed not only a lower computational cost and higher accuracy, but also a better explanation of some key phenomena of these two effects, such as new concept generation and anti-background noise. This mesoscale network topology has much room for the future.
